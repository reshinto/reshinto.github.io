"use strict";(self.webpackChunkportfolio=self.webpackChunkportfolio||[]).push([[9801],{3905:(e,t,a)=>{a.d(t,{Zo:()=>m,kt:()=>h});var r=a(7294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},l=Object.keys(e);for(r=0;r<l.length;r++)a=l[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(r=0;r<l.length;r++)a=l[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var o=r.createContext({}),p=function(e){var t=r.useContext(o),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},m=function(e){var t=p(e.components);return r.createElement(o.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},c=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,l=e.originalType,o=e.parentName,m=s(e,["components","mdxType","originalType","parentName"]),c=p(a),h=n,d=c["".concat(o,".").concat(h)]||c[h]||u[h]||l;return a?r.createElement(d,i(i({ref:t},m),{},{components:a})):r.createElement(d,i({ref:t},m))}));function h(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var l=a.length,i=new Array(l);i[0]=c;var s={};for(var o in t)hasOwnProperty.call(t,o)&&(s[o]=t[o]);s.originalType=e,s.mdxType="string"==typeof e?e:n,i[1]=s;for(var p=2;p<l;p++)i[p]=a[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,a)}c.displayName="MDXCreateElement"},5695:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>o,contentTitle:()=>i,default:()=>u,frontMatter:()=>l,metadata:()=>s,toc:()=>p});var r=a(7462),n=(a(7294),a(3905));const l={},i="Parallel, Concurrent and Multithreading",s={unversionedId:"languageSpecific/java/parallelConcurrentMultithreading",id:"languageSpecific/java/parallelConcurrentMultithreading",title:"Parallel, Concurrent and Multithreading",description:"Parallel Computing Hardware",source:"@site/docs/languageSpecific/java/parallelConcurrentMultithreading.md",sourceDirName:"languageSpecific/java",slug:"/languageSpecific/java/parallelConcurrentMultithreading",permalink:"/docs/languageSpecific/java/parallelConcurrentMultithreading",draft:!1,editUrl:"https://github.com/reshinto/reshinto.github.io/blob/dev/docs/languageSpecific/java/parallelConcurrentMultithreading.md",tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Memory Management",permalink:"/docs/languageSpecific/java/memoryManagement"},next:{title:"Python",permalink:"/docs/languageSpecific/python/"}},o={},p=[{value:"Parallel Computing Hardware",id:"parallel-computing-hardware",level:2},{value:"Sequential vs Parallel computing",id:"sequential-vs-parallel-computing",level:3},{value:"sequential",id:"sequential",level:4},{value:"parallel",id:"parallel",level:4},{value:"Parallel computing hardware",id:"parallel-computing-hardware-1",level:3},{value:"Shared vs distributed memory",id:"shared-vs-distributed-memory",level:3},{value:"Threads and Processes",id:"threads-and-processes",level:2},{value:"Threads vs process",id:"threads-vs-process",level:3},{value:"Concurrent vs Parallel execution",id:"concurrent-vs-parallel-execution",level:3},{value:"Concurrency",id:"concurrency",level:4},{value:"Parallel",id:"parallel-1",level:4},{value:"Execution Scheduling",id:"execution-scheduling",level:3}],m={toc:p};function u(e){let{components:t,...l}=e;return(0,n.kt)("wrapper",(0,r.Z)({},m,l,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"parallel-concurrent-and-multithreading"},"Parallel, Concurrent and Multithreading"),(0,n.kt)("h2",{id:"parallel-computing-hardware"},"Parallel Computing Hardware"),(0,n.kt)("h3",{id:"sequential-vs-parallel-computing"},"Sequential vs Parallel computing"),(0,n.kt)("h4",{id:"sequential"},"sequential"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"program is broken down into a sequence of discrete instructions that are executed one after another"),(0,n.kt)("li",{parentName:"ul"},"only can execute 1 instruction at any given moment"),(0,n.kt)("li",{parentName:"ul"},"limitations",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"the time it takes for a sequential program to run is limited by the speed of the processor",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"and how fast it can execute that series of instructions")))))),(0,n.kt)("h4",{id:"parallel"},"parallel"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"breaking the tasks for them to be executed simultaneously by different processors",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"accomplish a single task faster"),(0,n.kt)("li",{parentName:"ul"},"accomplish more tasks in a given time"))),(0,n.kt)("li",{parentName:"ul"},"the processors has to coordinate with each other as they might be dependent on each other",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"does not necessarily means speed will become twice as fast",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"if a separate task B requires task A but task A is still processing even though task B is completed"),(0,n.kt)("li",{parentName:"ul"},"the entire process will have to wait until task A is completed"))),(0,n.kt)("li",{parentName:"ul"},"this adds complexity")))),(0,n.kt)("h3",{id:"parallel-computing-hardware-1"},"Parallel computing hardware"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"parallel computing requires parallel hardware"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"with multiple processors to execute different parts of a program at the same time"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"different structural types of parallel computers"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("inlineCode",{parentName:"p"},"Flynn's Taxonomy"),": 1 of most widely used systems for classifying multiprocessor architectures"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Flynn Taxonomy",src:a(8855).Z,width:"1216",height:"710"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Single Instruction Single Data (SISD)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"SISD",src:a(4257).Z,width:"882",height:"878"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"simplest of the 4 classes"),(0,n.kt)("li",{parentName:"ul"},"it is the sequential computer with a single processor unit",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"at any given time, can only execute 1 series of instructions and act on 1 element of data at a time"))))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Single Instruction Multiple DATA (SIMD)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"SIMD",src:a(1249).Z,width:"874",height:"866"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"a type of parallel computer with multiple processing units"),(0,n.kt)("li",{parentName:"ul"},"all of its processors execute the same instruction at any given time",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"but they can operate on different data element"))),(0,n.kt)("li",{parentName:"ul"},"this type of SIMD architecture is well suited for apps that perform the same handful of operations on a massive set of data elements",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"e.g.: image processing",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"most modern computers use graphic processing units (GPU) with SIMD instructions to do it"))))))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Multiple Instruction Single Data (MISD)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"MISD",src:a(6703).Z,width:"878",height:"874"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"the opposite of ",(0,n.kt)("inlineCode",{parentName:"li"},"SIMD")),(0,n.kt)("li",{parentName:"ul"},"each processing unit independently executes its own separate series of instructions",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"however, all of those processors are operating on the same single stream of data"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("inlineCode",{parentName:"li"},"MISD")," doesn't make much practical sense, thus its not a commonly used architecture"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Multiple Instruction Multiple Data (MIMD)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"MIMD",src:a(8638).Z,width:"862",height:"862"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"every processing unit can be operating on a different set of data")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"it is the most commonly used architecture")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"can find it in multicore PCs, network clusters, supercomputers")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"can be further subdivided into 2 parallel programming models"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Single Program Multiple Data (SPMD)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"SPMD",src:a(7819).Z,width:"1174",height:"408"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"multiple processing units are executing a copy of the same single program simultaneously",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"but each can use different data"))),(0,n.kt)("li",{parentName:"ul"},"different from ",(0,n.kt)("inlineCode",{parentName:"li"},"SIMD")," because although each processor is executing the same program",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"they do not have to be executing the same instruction at the same time"),(0,n.kt)("li",{parentName:"ul"},"the processors can run asynchronously"),(0,n.kt)("li",{parentName:"ul"},"the program usually includes conditional logic that allows different tasks within the program to only execute specific parts of the overall program"))),(0,n.kt)("li",{parentName:"ul"},"it is the most common style of parallel programming"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Multiple Program Multiple Data (MPMD)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"MPMD",src:a(7810).Z,width:"1536",height:"782"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"each processors is executing a different program"),(0,n.kt)("li",{parentName:"ul"},"processors can be executing different, independent programs at the same time while also be operating on different data"),(0,n.kt)("li",{parentName:"ul"},"typically in this model, 1 processing node will be selected as the host or manager",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"which runs 1 program that farms out data to the other nodes running a 2nd program"),(0,n.kt)("li",{parentName:"ul"},"those other nodes do their work and return their results to the manager"))),(0,n.kt)("li",{parentName:"ul"},"it is not as common as ",(0,n.kt)("inlineCode",{parentName:"li"},"SPMD")," but can be useful for some applications that lend themselves to functional decomposition")))))))))))),(0,n.kt)("h3",{id:"shared-vs-distributed-memory"},"Shared vs distributed memory"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"accessing memory needs to be fast enough to get the instructions and data required in order to be able to make use of more processors")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"computer memory usually operates at a much slower speed than processors")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"when 1 processor is reading or writing to memory, it often prevents any other processors from accessing the same memory element"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Memory and processor",src:a(1105).Z,width:"1342",height:"836"}))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"there are 2 main memory architectures that exists for parallel computing"),(0,n.kt)("ol",{parentName:"li"},(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},"shared memory"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"all processors have access to the same memory as part of a global address space"),(0,n.kt)("li",{parentName:"ul"},"although each processor operates independently",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"if 1 processor changes a memory location, all of the other processor operates will see that change"))),(0,n.kt)("li",{parentName:"ul"},"the term shared memory does not mean all data exists on the same physical device",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"it could be spread across a cluster of systems")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"the key is that both of the processors see everything that happens in the shared memory space")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"the shared memory architectures have the advantage of being easier for programming in regards to memory"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"because its easier to share data between different parts of a parallel program"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"disadvantage is that they don't often scale well"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"adding more processors to a shared memory system will increase traffic on the shared memory bus"),(0,n.kt)("li",{parentName:"ul"},"shared memory puts responsibility on the programmer to synchronize memory accesses to ensure correct behavior"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"often classified into 1 of 2 categories, which are based on how the processors are connected to memory and how quickly they can access it"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Uniform memory access (UMA)"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"all of the processors have equal access to the memory",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"means that they can access it equally fast"))),(0,n.kt)("li",{parentName:"ul"},"several types of UMA architectures",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"most common is ",(0,n.kt)("inlineCode",{parentName:"p"},"symmetric multiprocessing system")," (SMP)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Symmetric Multiprocessing",src:a(7035).Z,width:"1584",height:"906"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"has 2 or more identical processors which are connected to a single shared memory often through a system bus"),(0,n.kt)("li",{parentName:"ul"},"in modern multicore processors, each of the processing cores are treated as a separate processor"),(0,n.kt)("li",{parentName:"ul"},"in most modern processors, each core has its own cache",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"it is a small and very fast piece of memory that only it can see and it uses it to store data that it's frequently working with"),(0,n.kt)("li",{parentName:"ul"},"however, caches introduces the challenge that if 1 processor copies a value from the shared main memory, then makes a change to it in its local cache",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"that change needs to be updated back in the shared memory before another processor reads the old value, which is no longer current"),(0,n.kt)("li",{parentName:"ul"},"this issue is called ",(0,n.kt)("inlineCode",{parentName:"li"},"cache coherency")),(0,n.kt)("li",{parentName:"ul"},"handled by the hardware in multicore processors"))))))))))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Non-uniform memory access (NUMA)"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Non-uniform memory access",src:a(2674).Z,width:"1656",height:"754"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"often made by physically connecting multiple ",(0,n.kt)("inlineCode",{parentName:"li"},"SMP")," systems together"),(0,n.kt)("li",{parentName:"ul"},"the access is nonuniform because some processors will have quicker access to certain parts of memory than others"),(0,n.kt)("li",{parentName:"ul"},"it takes longer to access things over the bus"),(0,n.kt)("li",{parentName:"ul"},"overall, every processor can still see everything in memory"))))))))),(0,n.kt)("li",{parentName:"ol"},(0,n.kt)("p",{parentName:"li"},"distributed memory"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Distributed Memory",src:a(9330).Z,width:"1642",height:"748"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"in a distributed memory system, each processor has its own local memory with its own address space"),(0,n.kt)("li",{parentName:"ul"},"concept of a global address space doesn't exist"),(0,n.kt)("li",{parentName:"ul"},"all the processors are connected through some sort of network, which can be as simple as ",(0,n.kt)("inlineCode",{parentName:"li"},"Ethernet")),(0,n.kt)("li",{parentName:"ul"},"each processor operates independently",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"if it makes changes to its local memory, that change is not automatically reflected in the memory of other processors"),(0,n.kt)("li",{parentName:"ul"},"it is up to the programmers to explicitly define how and when data is communicated between the nodes in a distributed system",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"this is a disadvantage"))))),(0,n.kt)("li",{parentName:"ul"},"advatange of a distributed memory architecture is that its scalable",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"when more processors are added to the system, memory also increases"),(0,n.kt)("li",{parentName:"ul"},"it makes it cost effector to use commodity, of the shelf computers and networking equipment to build large distributed memory systems"))),(0,n.kt)("li",{parentName:"ul"},"most supercomputers use some form of distributed memory architecture or a hybrid of distributed and shared memory")))))),(0,n.kt)("h2",{id:"threads-and-processes"},"Threads and Processes"),(0,n.kt)("h3",{id:"threads-vs-process"},"Threads vs process"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Threads and Process",src:a(4391).Z,width:"1574",height:"810"})),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"the concept of 2 people doing the same thing such as cooking",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"each person is a thread, while the cooking is the process"),(0,n.kt)("li",{parentName:"ul"},"both person work independently contributing to the cooking process"),(0,n.kt)("li",{parentName:"ul"},"both have direct access to the same cookbooks containing cooking instructions data"),(0,n.kt)("li",{parentName:"ul"},"the ingredients being used represents the data and variables being manipulated"),(0,n.kt)("li",{parentName:"ul"},"however, this will cause problems if there are poor coordination between the people (threads)"))),(0,n.kt)("li",{parentName:"ul"},"process",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"it is the instance of the program executing when an application runs on a computer"),(0,n.kt)("li",{parentName:"ul"},"the process consists of the program's code, data, and information about its state"),(0,n.kt)("li",{parentName:"ul"},"each process is independent and has its own separate address space in memory"),(0,n.kt)("li",{parentName:"ul"},"a computer can have hundreds of active processes at once",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"the operating system's job is to manage all of these"))),(0,n.kt)("li",{parentName:"ul"},"sharing resources between separate processes is not as easy as sharing between threads in the same process",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"because every process exists in its own address space"),(0,n.kt)("li",{parentName:"ul"},"example",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"2 kitchens (processes), 2 person (thread) in each kitchen, working on different recipes (program)",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"each kitchen have their own ingredients and you can't access the ingredients from a different kitchen"))))),(0,n.kt)("li",{parentName:"ul"},"there are ways to communicate and share data between processes, but requires more work than communicating between threads"))))),(0,n.kt)("li",{parentName:"ul"},"threads",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"within every process, there are 1 or more smaller sub elements called ",(0,n.kt)("inlineCode",{parentName:"li"},"threads"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"these are similar to a tiny processes"))),(0,n.kt)("li",{parentName:"ul"},"each thread",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"is an independent path of execution through the program"),(0,n.kt)("li",{parentName:"ul"},"a different sequence of instructions"),(0,n.kt)("li",{parentName:"ul"},"can only exist as part of a process"))),(0,n.kt)("li",{parentName:"ul"},"threads are the basic units that the operating system manages"),(0,n.kt)("li",{parentName:"ul"},"it allocates time on the processor to execute them"),(0,n.kt)("li",{parentName:"ul"},"threads that belong to the same process share the processes address space",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"it gives them access to the same resources in memory including the program's executable code and data"))))),(0,n.kt)("li",{parentName:"ul"},"communication between processes",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"e.g.:",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"use system provided Inter-Process Communication (IPC) mechanisms like Sockets and pipes"),(0,n.kt)("li",{parentName:"ul"},"allocating special inter-process shared memory space"),(0,n.kt)("li",{parentName:"ul"},"using remote procedure calls"))))),(0,n.kt)("li",{parentName:"ul"},"writing parallel programs that use multiple processes working together towards a common goal or using multiple threads within a single process",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"which to use depends on what you are doing and the environment it's running",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"because implementation of threads and processes differs between operating systems and programming languages"),(0,n.kt)("li",{parentName:"ul"},"if the application is going to be distributed across multiple computers, it would be better to separate processes for it"),(0,n.kt)("li",{parentName:"ul"},"but as a rule of thumb, if can structure the program to take advantage of multiple threads, stick to using threads than using multiple processes",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"because threads are considered lightweight compared to processes, which are more resource intensive"),(0,n.kt)("li",{parentName:"ul"},"a thread requires less overhead to create and terminate than a process"),(0,n.kt)("li",{parentName:"ul"},"using multiple threads is usally faster for an operating system to switch between executing threads from the same process than to switch between different processes")))))))),(0,n.kt)("h3",{id:"concurrent-vs-parallel-execution"},"Concurrent vs Parallel execution"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"just because a program is structured to have multiple threads or processes does not mean they'll necessarily execute in parallel")),(0,n.kt)("table",null,(0,n.kt)("thead",{parentName:"table"},(0,n.kt)("tr",{parentName:"thead"},(0,n.kt)("th",{parentName:"tr",align:null},"Concurrency"),(0,n.kt)("th",{parentName:"tr",align:null},"Parallelism"))),(0,n.kt)("tbody",{parentName:"table"},(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Program Structure"),(0,n.kt)("td",{parentName:"tr",align:null},"Simultaneous Execution")),(0,n.kt)("tr",{parentName:"tbody"},(0,n.kt)("td",{parentName:"tr",align:null},"Dealing with multiple things at once"),(0,n.kt)("td",{parentName:"tr",align:null},"Doing multiple things at once")))),(0,n.kt)("h4",{id:"concurrency"},"Concurrency"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"it refers to the ability of an algorithm or program to be broken into parts that can run independently of each other"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"they are order independent"),(0,n.kt)("li",{parentName:"ul"},"e.g.: in a salad recipe, chopping lettuce, cucumbers, tomatoes etc can be done concurrently by different people and the order is not important"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Concurrent Execution"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"single processor"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Single Processor Concurrent Execution",src:a(2285).Z,width:"1578",height:"760"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"only 1 task can be executed at any instant in time"),(0,n.kt)("li",{parentName:"ul"},"different tasks will be swap and take turns to be executed"),(0,n.kt)("li",{parentName:"ul"},"if tasks are swapped frequently",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"it creates the illusion that it is executing simultaneously on the single processor, but is not true parallel execution"))))))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Concurrent programming is useful for I/O dependent tasks like graphical user interfaces"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"when user clicks a button to execute an operation"),(0,n.kt)("li",{parentName:"ul"},"to avoid locking up the user interface until it is completed",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"we can run the operation in a spearate concurrent thread",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"thus leaving the thread that's running the UI free to accept new inputs")))))))),(0,n.kt)("h4",{id:"parallel-1"},"Parallel"),(0,n.kt)("p",null,(0,n.kt)("img",{alt:"Multi Processor Parallel Execution",src:a(4080).Z,width:"1564",height:"740"})),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},"requires parallel hardware in order to execute in parallel",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"types of parallel hardward",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Multi-Core Processors",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"used mostly in desktop computers and cellphones"))),(0,n.kt)("li",{parentName:"ul"},"Graphics Processing Unit",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"contains hundreds or thousands of specialized cores working in parallel to make amazing graphics"))),(0,n.kt)("li",{parentName:"ul"},"Computer Cluster",(0,n.kt)("pre",{parentName:"li"},(0,n.kt)("code",{parentName:"pre"},"- distribute their processing across multiple systems\n"))))))),(0,n.kt)("li",{parentName:"ul"},"programs may not always benefit from parallel execution",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"e.g.: software drivers that handles I/O devices (mouse, keyboard, hard drive)",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"they are managed by the operating system as independent things that get executed"),(0,n.kt)("li",{parentName:"ul"},"in a multi-core system, the execution of those drivers might get split amongst the available processors"),(0,n.kt)("li",{parentName:"ul"},"however, since I/O operations occur infrequently, relative to the speed at which computer operates, nothing is gain from parallel execution"),(0,n.kt)("li",{parentName:"ul"},"thus it can run on a single processor without any difference"))))),(0,n.kt)("li",{parentName:"ul"},"parallel processing becomes useful for computationally intensive tasks",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"such as calculating the result of multiplying 2 matrices together"),(0,n.kt)("li",{parentName:"ul"},"when large math operations can be devided into independent subparts, executing those parts in parallel on separate processors can speed things up")))),(0,n.kt)("h3",{id:"execution-scheduling"},"Execution Scheduling"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"threads don't execute when they want to")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"the Operating System includes a scheduler that controls when different threads and processes get their turn to execute on the CPU")),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"the ",(0,n.kt)("inlineCode",{parentName:"p"},"scheduler")," makes it possible for multiple programs to run concurrently on a single processor"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"when a process is created and ready to run, it gets loaded into memory and placed in the ready queue"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Scheduler Ready Queue",src:a(4786).Z,width:"808",height:"894"})))),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"the scheduler cycles through the ready processes so that they get a chance to execute on the processor"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Scheduler Cycle Ready Queue",src:a(4179).Z,width:"1614",height:"882"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"if there are multiple processors, the OS will schedule processors to run on each of them to make the most use of the additional resources"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Scheduler Cycle Ready Queue Multi Processors",src:a(5933).Z,width:"1616",height:"886"}))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"a process will run until it finishes, then the scheduler will assign another process to execute on that processor"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Scheduler Process Ends",src:a(1421).Z,width:"809",height:"438"}))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"or a process might get blocked and have to wait for an I/O event"),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Scheduler IO Queue",src:a(1240).Z,width:"809",height:"438"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"in this case, it will go into a separate I/O waiting queue so that another process can run"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"or scheduler might determine that a process has spent its fair share of time on the processor and swap it out for another process from the ready queue, also referred to as ",(0,n.kt)("inlineCode",{parentName:"p"},"context switch")),(0,n.kt)("p",{parentName:"li"},(0,n.kt)("img",{alt:"Scheduler Context Switch",src:a(4392).Z,width:"809",height:"438"})),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"the OS has to save the state or context of the process that was running so that it can be resumed later"),(0,n.kt)("li",{parentName:"ul"},"then it has to load the context of the new process that is about to run"),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("inlineCode",{parentName:"li"},"context switches")," are not instantaneous",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"it takes time to save and restore the registers and memory state"),(0,n.kt)("li",{parentName:"ul"},"thus the scheduler needs a strategy for how frequently it switches between processes",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("inlineCode",{parentName:"li"},"Scheduling Algorithms"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"First come, first served"),(0,n.kt)("li",{parentName:"ul"},"Shortest job next"),(0,n.kt)("li",{parentName:"ul"},"Priority"),(0,n.kt)("li",{parentName:"ul"},"Shortest remaining time"),(0,n.kt)("li",{parentName:"ul"},"Round-robin"),(0,n.kt)("li",{parentName:"ul"},"Multiple level queues"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("inlineCode",{parentName:"li"},"Preemptive Algorithms"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"a running low priority task might pause or preempt when a higher prioty task enters the ready state"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("inlineCode",{parentName:"li"},"Non-preemptive Algorithms"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"once a process enters the ready state, it'll be allowed to run for its allotted time"))))))))))))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"Which scheduling algorithm is used by the OS depends which of the following scheduling goals is required"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"maximize throughput"),(0,n.kt)("li",{parentName:"ul"},"maximize fairness"),(0,n.kt)("li",{parentName:"ul"},"minimize wait time"),(0,n.kt)("li",{parentName:"ul"},"minimize latency"))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},"we might not have any control over when the parts of the program gets executed as it is often handled under the hood by the OS"))))}u.isMDXComponent=!0},9330:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/distibutedMemory-ca6ea12e8b9af15ed0e71e93d59b1b5c.png"},8855:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/flynnTaxonomy-134c7a48ccf6f1aa60c18d794dd30b92.png"},1105:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/memoryProcessor-b5d21d902226af35fb7d668d5603febf.png"},8638:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/mimd-32960ce1ec9220a63f492f1057833054.png"},6703:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/misd-eddc5c5e659165703dd6673fcbaf1f9b.png"},4080:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/multiProcessorParallelExecution-d5ed0c1fb2ff828ed1cdebe362b4893d.png"},7810:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/multipleProgramMultipleData-15b6c0a82e6432c526cd927c7132afed.png"},2674:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/numa-49c35f1e2bca5f0f34b2163cfcfa5638.png"},4392:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/schedulerContextSwitch-9cd998f331447ddb51febef7d1fc7f01.gif"},4179:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/schedulerCycleReadyQueue-db7548daf8679861cb7d5345aa54ff14.png"},5933:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/schedulerCycleReadyQueueMultiProcessors-4e9f2b4251d4d34cd47538108b61080e.png"},1240:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/schedulerIOQueue-5fccb07d8b9ffe82d662256fdb30897d.gif"},1421:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/schedulerProcessEnds-168e1b277238bb2c6cbea07edfbf5520.gif"},4786:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/schedulerReadyQueue-3d1c92450e9a315d2ae01bd0cdfdd189.png"},1249:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/simd-8b94a0628dadb33fb30fbd506edb158d.png"},2285:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/singleProcessorConcurrentExecution-755917cfaec7e326527b509f5dbd9b5a.png"},7819:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/singleProgramMultipleData-987de645c608b5a3d75820df55f1d4af.png"},4257:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/sisd-e91ac9c14f04260a26bf330eab85853b.png"},7035:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/smp-d7d7eb6cde1c7194adaef2c518967912.png"},4391:(e,t,a)=>{a.d(t,{Z:()=>r});const r=a.p+"assets/images/threadsAndProcess-bd75bcde2fb9cfa42cdd122fdb7f5a37.png"}}]);